# Проект: Сервис для восстановления и прогнозирования пространственно-временных рядов

## Описание
Этот проект предназначен для создания сервиса на Python, который решает задачи восстановления и прогнозирования пространственно-временных рядов с использованием предобученных LLM и специализированных библиотек для работы с такими данными.

### Основные компоненты:
- API-сервис (FastAPI)
- Интеграция с LLM (например, HuggingFace Transformers / локальная модель)
- Библиотеки для пространственно-временных рядов: PySTEPS, sktime, tslearn, torch-geometric
- Примеры существующих решений для сравнения

## Примеры существующих решений
- PySTEPS: библиотека для прогнозирования осадков на основе радарных данных
- sktime: библиотека для анализа и прогнозирования временных рядов
- tslearn: инструменты для машинного обучения на временных рядах
- torch-geometric: глубокое обучение на графах, включая пространственно-временные данные
- ST-Transformer: архитектура для моделирования пространственно-временных зависимостей

## Структура проекта
- `app/` — исходный код сервиса
- `notebooks/` — примеры и эксперименты
- `tests/` — тесты
- `requirements.txt` — зависимости
- `README.md` — документация

## Запуск и установка
1. Установите зависимости: `pip install -r requirements.txt`
2. Запустите сервис: `uvicorn app.main:app --reload`

## Локальная LLM (transformers / Ollama)

Модуль `app.llm` поддерживает локальную генерацию через Hugging Face `transformers`.
Для использования локальной модели задайте переменную окружения `HF_MODEL` с именем модели (например, `local/llama2` или любой доступный путь).

Если `HF_MODEL` не задан или загрузка модели не удалась, модуль использует rules-based fallback-логики для выбора библиотеки (`pysteps`, `sktime`, `tslearn`, `torch_geometric`).

Пример использования без установки тяжёлых зависимостей (быстрый smoke-test):

1. Создайте виртуальное окружение и активируйте его.
2. Установите минимальные dev-зависимости:

```bash
python3 -m pip install fastapi uvicorn pytest
```

3. Запустите тесты fallback-логики (они не требуют `transformers` и `pysteps`):

```bash
python3 -m pytest tests/test_llm.py -q
```

Дополнительная информация про конкретную модель
---------------------------------------------

`select_model` теперь может возвращать два опциональных поля `model_name` и `model_args` в дополнение к `library` и `model_choice`.

- `model_name` — строка с названием предложенной модели/режима (например, `AutoARIMA`, `AutoETS`, `RandomForestReduction`, `GAT`).
- `model_args` — словарь с параметрами, которые будет принимать раннер (например, `{"n_estimators": 100}`).

Функция `run_model_from_choice` передаёт эти поля раннеру (если они заданы). Это позволяет LLM предлагать не только библиотеку, но и конкретный алгоритм и небольшие параметры для него.


Примечание: CLI-скрипты (`scripts/*.py`) теперь сами добавляют корень репозитория в `sys.path`, поэтому запускать их можно напрямую без `PYTHONPATH`.
Для запуска тестов по-прежнему удобно использовать:

```bash
PYTHONPATH=. pytest
# или установить пакет в editable режиме
pip install -e .
```

Примечание про `pysteps` и сборку: `pysteps` содержит нативные расширения и требует системных пакетов (C-компилятор, OpenMP и т.д.). Если установка через `pip` падает, можно:
- установить системные зависимости (`build-essential`, `gcc`, `g++`, `libopenblas-dev`, `liblapack-dev` и т.д.),
- или пропустить установку `pysteps` в `requirements.txt` и использовать fallback для тестирования.

## TODO
- Реализовать REST API для загрузки и обработки данных
- Интегрировать LLM для генерации прогнозов и восстановления
- Добавить примеры сравнения с существующими решениями
